{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a4627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = [437.620, 468.010, 463.439]\n",
    "\n",
    "mean = np.mean(x)\n",
    "\n",
    "y = []\n",
    "for value in x:\n",
    "    y.append(value - mean)\n",
    "\n",
    "std_div = np.std(x)\n",
    "\n",
    "print(x)\n",
    "print(mean)\n",
    "print(y)\n",
    "print(std_div)\n",
    "\n",
    "print(f\"rsd: {(std_div / mean):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = [23.117, 22.511, 22.637, 22.260, 22.333]\n",
    "\n",
    "mean = np.mean(x)\n",
    "\n",
    "y = []\n",
    "for value in x:\n",
    "    y.append(value - mean)\n",
    "\n",
    "std_div = np.std(x)\n",
    "\n",
    "print(x)\n",
    "print(mean)\n",
    "print(y)\n",
    "print(std_div)\n",
    "\n",
    "x = [53.259, 51.949, 53.838, 53.082, 51.183]\n",
    "\n",
    "mean = np.mean(x)\n",
    "\n",
    "y = []\n",
    "for value in x:\n",
    "    y.append(value - mean)\n",
    "\n",
    "std_div = np.std(x)\n",
    "\n",
    "print(x)\n",
    "print(mean)\n",
    "print(y)\n",
    "print(std_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84b2d579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improved by: 16.28%\n"
     ]
    }
   ],
   "source": [
    "print(f\"improved by: {(1- 9 / 10.75):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ce27bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-time: 8.897380865125715 is faster than 10.554019192177146 by: 15.70%\n",
      "mean-time: 10.554019192177146 is 1.19x slower than 8.897380865125715\n",
      "throughput: 4.050013714414441 is faster than 4.770756788661214 by: 15.11%\n",
      "throughput: 4.770756788661214 is 1.18x slower than 4.050013714414441\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json(\"data/plotting/plotting_bench_python.json\")\n",
    "\n",
    "\n",
    "df = df[df[\"engine\"].isin([\"netcdf4-python-parallel\", \"hdf5-python-parallel\"])]\n",
    "\n",
    "#df = df[~df[\"engine\"].isin([\"netcdf4-python\", \"hdf5-python\", \"zarr-python\"])]\n",
    "\n",
    "#df = df[~df[\"total filesize\"].isin([\"30.0 GB\", \"40.0 GB\", \"50.0 GB\", \"60.0 GB\", \"70.0 GB\"])]\n",
    "\n",
    "#df = df[~(df[\"engine\"].isin([\"netcdf4-python\"])) | (df[\"total filesize\"].isin([\"10.0 GB\", \"20.0 GB\", \"30.0 GB\", \"40.0 GB\"]))]\n",
    "#df = df[~(df[\"engine\"].isin([\"hdf5-python\"])) | (df[\"total filesize\"].isin([\"10.0 GB\", \"20.0 GB\", \"70.0 GB\"]))]\n",
    "\n",
    "#df = df[df[\"total filesize\"].isin([\"10.0 GB\", \"20.0 GB\", \"30.0 GB\", \"40.0 GB\"])]\n",
    "#df = df[df[\"total filesize\"].isin([\"10.0 GB\", \"20.0 GB\", \"70.0 GB\"])]\n",
    "\n",
    "res = {}\n",
    "res2 = []\n",
    "col_mean_seq = []\n",
    "col_mean_par = []\n",
    "throu_seq = []\n",
    "throu_par = []\n",
    "format1 = []\n",
    "format2 = []\n",
    "format3 = []\n",
    "format4 = []\n",
    "\n",
    "filter = df[\"format\"].drop_duplicates(ignore_index=True)\n",
    "smth = pd.DataFrame()\n",
    "for format in filter:\n",
    "    mask = df[\"format\"].values == format\n",
    "    df_format = df[mask]\n",
    "    \n",
    "    std_div =  np.std(df_format[\"time taken\"].to_list())\n",
    "    mean =  np.mean(df_format[\"time taken\"].to_list())\n",
    "    \n",
    "    \n",
    "    #print(f\"std_div: {std_div} and mean: {mean} for format {format}\")\n",
    "    \n",
    "    rsd = std_div / mean\n",
    "    \n",
    "    res[format] = f\"{rsd:.2%}\"\n",
    "    \n",
    "    #df_format[\"engine\"].iat[0] == \"netcdf4-python\" or  df_format[\"engine\"].iat[0] == \"hdf5-python\" or df_format[\"engine\"].iat[0] == \"zarr-python\"\n",
    "    \n",
    "    if df_format[\"engine\"].iat[0] == \"netcdf4-python-parallel\":\n",
    "        col_mean_seq.append(mean)\n",
    "        format1.append(format)\n",
    "    else:\n",
    "        col_mean_par.append(mean)\n",
    "        format2.append(format)\n",
    "        \n",
    "    res2.append(rsd)\n",
    "    \n",
    "    str_filesize = df_format[\"total filesize\"].iat[0]\n",
    "    filesize = float(str_filesize.split()[0])\n",
    "\n",
    "    throughput = filesize / mean\n",
    "    \n",
    "    if df_format[\"engine\"].iat[0] == \"netcdf4-python-parallel\":\n",
    "        throu_seq.append(throughput)\n",
    "        format3.append(format)\n",
    "    else:\n",
    "        throu_par.append(throughput)\n",
    "        format4.append(format)\n",
    "    \n",
    "    \n",
    "    #print(f\"rsd: {np.round(rsd, decimals=3)}%\")\n",
    "    \n",
    "#print(col_mean)\n",
    "#print(f\"sequential means: {col_mean_seq} \\nformat: {format1} \\n\")\n",
    "#print(f\"parallel means: {col_mean_par} \\nformat: {format2} \\n\")\n",
    "\n",
    "mean = np.ndarray(shape=2)\n",
    "mean[0] = np.mean(col_mean_seq)\n",
    "mean[1] = np.mean(col_mean_par)\n",
    "\n",
    "#print(mean)\n",
    "\n",
    "print(f\"mean-time: {mean.min()} is faster than {mean.max()} by: {(1- mean.min() / mean.max()):.02%}\")\n",
    "\n",
    "print(f\"mean-time: {mean.max()} is {(mean.max() / mean.min()):.3}x slower than {mean.min()}\")\n",
    "\n",
    "#print(f\"sequential throughput: {throu_seq} \\nformat: {format3} \\n\")\n",
    "#print(f\"parallel throughput: {throu_par} \\nformat: {format4} \\n\")\n",
    "\n",
    "tmean = np.ndarray(shape=2)\n",
    "tmean[0] = np.mean(throu_seq)\n",
    "tmean[1] = np.mean(throu_par)\n",
    "\n",
    "#print(tmean)\n",
    "\n",
    "print(f\"throughput: {tmean.min()} is faster than {tmean.max()} by: {(1- tmean.min() / tmean.max()):.02%}\")\n",
    "\n",
    "print(f\"throughput: {tmean.max()} is {(tmean.max() / tmean.min()):.3}x slower than {tmean.min()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1fb893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-time: 18.05403086666667 is faster than 41.00133686666667 by: 55.97%\n",
      "mean-time: 41.00133686666667 is 2.27x slower than 18.05403086666667\n",
      "throughput: 0.6986463265601898 is faster than 1.5876156427219448 by: 55.99%\n",
      "throughput: 1.5876156427219448 is 2.27x slower than 0.6986463265601898\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json(\"data/plotting/plotting_bench_c.json\")\n",
    "\n",
    "#df = df[~df[\"engine\"].isin([\"hdf5-subfiling\"])]\n",
    "df = df[df[\"engine\"].isin([\"hdf5-c\", \"netcdf4-c\"])]\n",
    "#df = df[~df[\"total filesize\"].isin([\"20.0 GB\"])]\n",
    "\n",
    "#df = df[~df[\"total filesize\"].isin([\"30.0 GB\", \"40.0 GB\", \"50.0 GB\", \"60.0 GB\", \"70.0 GB\"])]\n",
    "\n",
    "#df = df[~(df[\"engine\"].isin([\"netcdf4-c\"])) | ~(df[\"total filesize\"].isin([\"30.0 GB\", \"40.0 GB\", \"60.0 GB\", \"70.0 GB\"]))]\n",
    "#df = df[~(df[\"engine\"].isin([\"hdf5-python\"])) | (df[\"total filesize\"].isin([\"10.0 GB\", \"20.0 GB\", \"70.0 GB\"]))]\n",
    "\n",
    "df = df[~df[\"total filesize\"].isin([\"30.0 GB\", \"40.0 GB\", \"60.0 GB\", \"70.0 GB\"])]\n",
    "#df = df[df[\"total filesize\"].isin([\"10.0 GB\", \"20.0 GB\", \"70.0 GB\"])]\n",
    "\n",
    "res = {}\n",
    "res2 = []\n",
    "col_mean_seq = []\n",
    "col_mean_par = []\n",
    "throu_seq = []\n",
    "throu_par = []\n",
    "format1 = []\n",
    "format2 = []\n",
    "format3 = []\n",
    "format4 = []\n",
    "\n",
    "filter = df[\"format\"].drop_duplicates(ignore_index=True)\n",
    "smth = pd.DataFrame()\n",
    "for format in filter:\n",
    "    mask = df[\"format\"].values == format\n",
    "    df_format = df[mask]\n",
    "    \n",
    "    std_div =  np.std(df_format[\"time taken\"].to_list())\n",
    "    mean =  np.mean(df_format[\"time taken\"].to_list())\n",
    "    \n",
    "    \n",
    "    #print(f\"std_div: {std_div} and mean: {mean} for format {format}\")\n",
    "    \n",
    "    rsd = std_div / mean\n",
    "    \n",
    "    res[format] = f\"{rsd:.2%}\"\n",
    "    \n",
    "    #df_format[\"engine\"].iat[0] == \"netcdf4-python\" or  df_format[\"engine\"].iat[0] == \"hdf5-python\" or df_format[\"engine\"].iat[0] == \"zarr-python\"\n",
    "    \n",
    "    if df_format[\"engine\"].iat[0] == \"netcdf4-c\":\n",
    "        col_mean_seq.append(mean)\n",
    "        format1.append(format)\n",
    "    else:\n",
    "        col_mean_par.append(mean)\n",
    "        format2.append(format)\n",
    "        \n",
    "    res2.append(rsd)\n",
    "    \n",
    "    str_filesize = df_format[\"total filesize\"].iat[0]\n",
    "    filesize = float(str_filesize.split()[0])\n",
    "\n",
    "    throughput = filesize / mean\n",
    "    \n",
    "    if df_format[\"engine\"].iat[0] == \"netcdf4-c\":\n",
    "        throu_seq.append(throughput)\n",
    "        format3.append(format)\n",
    "    else:\n",
    "        throu_par.append(throughput)\n",
    "        format4.append(format)\n",
    "    \n",
    "    \n",
    "    #print(f\"rsd: {np.round(rsd, decimals=3)}%\")\n",
    "    \n",
    "#print(col_mean)\n",
    "#print(f\"sequential means: {col_mean_seq} \\nformat: {format1} \\n\")\n",
    "#print(f\"parallel means: {col_mean_par} \\nformat: {format2} \\n\")\n",
    "\n",
    "mean = np.ndarray(shape=2)\n",
    "mean[0] = np.mean(col_mean_seq)\n",
    "mean[1] = np.mean(col_mean_par)\n",
    "\n",
    "#print(mean)\n",
    "\n",
    "print(f\"mean-time: {mean.min()} is faster than {mean.max()} by: {(1- mean.min() / mean.max()):.02%}\")\n",
    "\n",
    "print(f\"mean-time: {mean.max()} is {(mean.max() / mean.min()):.3}x slower than {mean.min()}\")\n",
    "\n",
    "#print(f\"sequential throughput: {throu_seq} \\nformat: {format3} \\n\")\n",
    "#print(f\"parallel throughput: {throu_par} \\nformat: {format4} \\n\")\n",
    "\n",
    "tmean = np.ndarray(shape=2)\n",
    "tmean[0] = np.mean(throu_seq)\n",
    "tmean[1] = np.mean(throu_par)\n",
    "\n",
    "#print(tmean)\n",
    "\n",
    "print(f\"throughput: {tmean.min()} is ahead by {tmean.max()} by: {(1- tmean.min() / tmean.max()):.02%}\")\n",
    "\n",
    "print(f\"throughput: {tmean.max()} is {(tmean.max() / tmean.min()):.3}x lower than {tmean.min()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1de42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-time: 8.897380865125715 is faster than 13.753472142857143 by: 35.31%\n",
      "mean-time: 13.753472142857143 is 1.55x slower than 8.897380865125715\n",
      "throughput: 3.4064292506189657 is faster than 4.770756788661214 by: 28.60%\n",
      "throughput: 4.770756788661214 is 1.4x slower than 3.4064292506189657\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json(\"data/plotting/plotting_bench_python.json\")\n",
    "df2 = pd.read_json(\"data/plotting/plotting_bench_c.json\")\n",
    "\n",
    "df = pd.concat([df, df2], ignore_index=True)\n",
    "\n",
    "#df = df[~df[\"engine\"].isin([\"netcdf4-python\", \"hdf5-python\", \"zarr-python\", \"netcdf4-c\", \"hdf5-c\", \"hdf5-subfiling\"])]\n",
    "#df = df[df[\"engine\"].isin([\"zarr-python\", \"hdf5-c\"])]\n",
    "df = df[df[\"engine\"].isin([\"netcdf4-python-parallel\", \"hdf5-c-parallel\"])]\n",
    "\n",
    "res = {}\n",
    "res2 = []\n",
    "col_mean_seq = []\n",
    "col_mean_par = []\n",
    "throu_seq = []\n",
    "throu_par = []\n",
    "format1 = []\n",
    "format2 = []\n",
    "format3 = []\n",
    "format4 = []\n",
    "\n",
    "filter = df[\"format\"].drop_duplicates(ignore_index=True)\n",
    "smth = pd.DataFrame()\n",
    "for format in filter:\n",
    "    mask = df[\"format\"].values == format\n",
    "    df_format = df[mask]\n",
    "    \n",
    "    std_div =  np.std(df_format[\"time taken\"].to_list())\n",
    "    mean =  np.mean(df_format[\"time taken\"].to_list())\n",
    "    \n",
    "    \n",
    "    #print(f\"std_div: {std_div} and mean: {mean} for format {format}\")\n",
    "    \n",
    "    rsd = std_div / mean\n",
    "    \n",
    "    res[format] = f\"{rsd:.2%}\"\n",
    "    \n",
    "    #df_format[\"engine\"].iat[0] == \"netcdf4-python\" or  df_format[\"engine\"].iat[0] == \"hdf5-python\" or df_format[\"engine\"].iat[0] == \"zarr-python\"\n",
    "    \n",
    "    if df_format[\"engine\"].iat[0] == \"netcdf4-python-parallel\":\n",
    "        col_mean_seq.append(mean)\n",
    "        format1.append(format)\n",
    "    else:\n",
    "        col_mean_par.append(mean)\n",
    "        format2.append(format)\n",
    "        \n",
    "    res2.append(rsd)\n",
    "    \n",
    "    str_filesize = df_format[\"total filesize\"].iat[0]\n",
    "    filesize = float(str_filesize.split()[0])\n",
    "\n",
    "    throughput = filesize / mean\n",
    "    \n",
    "    if df_format[\"engine\"].iat[0] == \"netcdf4-python-parallel\":\n",
    "        throu_seq.append(throughput)\n",
    "        format3.append(format)\n",
    "    else:\n",
    "        throu_par.append(throughput)\n",
    "        format4.append(format)\n",
    "    \n",
    "    \n",
    "    #print(f\"rsd: {np.round(rsd, decimals=3)}%\")\n",
    "    \n",
    "#print(col_mean)\n",
    "#print(f\"sequential means: {col_mean_seq} \\nformat: {format1} \\n\")\n",
    "#print(f\"parallel means: {col_mean_par} \\nformat: {format2} \\n\")\n",
    "\n",
    "mean = np.ndarray(shape=2)\n",
    "mean[0] = np.mean(col_mean_seq)\n",
    "mean[1] = np.mean(col_mean_par)\n",
    "\n",
    "#print(mean)\n",
    "\n",
    "print(f\"mean-time: {mean.min()} is faster than {mean.max()} by: {(1- mean.min() / mean.max()):.02%}\")\n",
    "\n",
    "print(f\"mean-time: {mean.max()} is {(mean.max() / mean.min()):.3}x slower than {mean.min()}\")\n",
    "\n",
    "#print(f\"sequential throughput: {throu_seq} \\nformat: {format3} \\n\")\n",
    "#print(f\"parallel throughput: {throu_par} \\nformat: {format4} \\n\")\n",
    "\n",
    "tmean = np.ndarray(shape=2)\n",
    "tmean[0] = np.mean(throu_seq)\n",
    "tmean[1] = np.mean(throu_par)\n",
    "\n",
    "#print(tmean)\n",
    "\n",
    "print(f\"throughput: {tmean.min()} is ahead by {tmean.max()} by: {(1- tmean.min() / tmean.max()):.02%}\")\n",
    "\n",
    "print(f\"throughput: {tmean.max()} is {(tmean.max() / tmean.min()):.3}x lower than {tmean.min()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c14da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json(\"data/plotting/plotting_bench_python_parallel.json\")\n",
    "\n",
    "df = df[~df[\"engine\"].isin([\"netcdf4-python\", \"hdf5-python\", \"zarr-python\"])]\n",
    "\n",
    "res = {}\n",
    "res2 = []\n",
    "\n",
    "filter = df[\"format\"].drop_duplicates(ignore_index=True)\n",
    "smth = pd.DataFrame()\n",
    "for format in filter:\n",
    "    mask = df[\"format\"].values == format\n",
    "    df_format = df[mask]\n",
    "    \n",
    "    std_div =  np.std(df_format[\"time taken\"].to_list())\n",
    "    mean =  np.mean(df_format[\"time taken\"].to_list())\n",
    "    \n",
    "    \n",
    "    #print(f\"std_div: {std_div} and mean: {mean} for format {format}\")\n",
    "    \n",
    "    rsd = std_div / mean\n",
    "    \n",
    "    res[format] = f\"{rsd:.2%}\"\n",
    "    res2.append(rsd)\n",
    "    \n",
    "    \n",
    "    #print(f\"rsd: {np.round(rsd, decimals=3)}%\")\n",
    "    \n",
    "print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d044902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false --no-raise-error\n",
    "import pandas as pd\n",
    "\n",
    "df_bench_c = pd.read_json(\"data/plotting/plotting_bench_c.json\")\n",
    "df_bench_c_copy = pd.read_json(\"data/plotting/plotting_bench_c copy.json\")\n",
    "df_bench_python = pd.read_json(\"data/plotting/plotting_bench_python.json\")\n",
    "df_bench_python_copy = pd.read_json(\"data/plotting/plotting_bench_python_parallel.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = df_bench_c\n",
    "\n",
    "save_image = False\n",
    "\n",
    "# python plotting\n",
    "\n",
    "# plot development in time taken by chunksize\n",
    "\n",
    "#df = df[~df[\"engine\"].isin([\"netcdf4-python-parallel\", \"hdf5-python-parallel\"])]\n",
    "\n",
    "filter = df[\"format\"].drop_duplicates(ignore_index=True)\n",
    "smth = pd.DataFrame()\n",
    "for format in filter:\n",
    "    mask = df[\"format\"].values == format\n",
    "    df_format = df[mask]\n",
    "    \n",
    "    mean =  np.mean(df_format[\"time taken\"].to_list())\n",
    "    str_filesize = df_format[\"total filesize\"].iat[0]\n",
    "    filesize = float(str_filesize.split()[0])\n",
    "    unit = f\"{str_filesize.split()[1]}/s\"\n",
    "\n",
    "    throughput = filesize / mean\n",
    "    \n",
    "    error = stats.sem(df_format[\"time taken\"].to_list())\n",
    "    \n",
    "    tmp = pd.DataFrame(data=[{\"error bar\": error, \"time taken\": df_format[\"time taken\"], \"mean time\": mean, \"format\": format, \"engine\": df_format[\"engine\"].iat[0], \"run\": df_format[\"run\"].iat[0], \"total filesize\": df_format[\"total filesize\"].iat[0], \"throughput\": throughput, \"unit\":unit}])\n",
    "    smth = pd.concat([smth, tmp], ignore_index=True)\n",
    "\n",
    "fig = px.line(\n",
    "    data_frame=smth, \n",
    "    log_y=True, \n",
    "    x=\"total filesize\", \n",
    "    y=\"mean time\", \n",
    "    color=\"engine\", \n",
    "    markers=True, \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"mean time\": \"mean time in seconds (s)\"},\n",
    "    error_y=\"error bar\",\n",
    "    color_discrete_map={\n",
    "        \"zarr-python\": '#56B4E9',\n",
    "        \"netcdf4-python\": '#4B0092',\n",
    "        \"hdf5-python\": '#117733',\n",
    "        \"netcdf4-python-parallel\": '#FFB000',\n",
    "        \"hdf5-python-parallel\": '#FF4430',\n",
    "    },\n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "if save_image: fig.write_image(\"images/python-line-total-filesize.svg\", width=900, height=500, scale=1)\n",
    "\n",
    "unit = smth[\"unit\"].iat[0]\n",
    "fig = px.bar(\n",
    "    data_frame=smth, \n",
    "    x=\"total filesize\", \n",
    "    y=\"throughput\", \n",
    "    color=\"engine\", \n",
    "    barmode='group', \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"throughput\": f\"throughput in {unit}\"},\n",
    "    color_discrete_map={\n",
    "        \"zarr-python\": '#56B4E9',\n",
    "        \"netcdf4-python\": '#4B0092',\n",
    "        \"hdf5-python\": '#117733',\n",
    "        \"netcdf4-python-parallel\": '#FFB000',\n",
    "        \"hdf5-python-parallel\": '#FF4430',\n",
    "    },\n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "if save_image: fig.write_image(\"images/python-box-datarate.svg\", width=900, height=500, scale=1)\n",
    "\n",
    "\n",
    "\n",
    "save_image = False\n",
    "\n",
    "\n",
    "filter = df[\"format\"].drop_duplicates(ignore_index=True)\n",
    "smth = pd.DataFrame()\n",
    "for format in filter:\n",
    "    mask = df[\"format\"].values == format\n",
    "    df_format = df[mask]\n",
    "    \n",
    "    std_div =  np.std(df_format[\"time taken\"].to_list())\n",
    "    mean =  np.mean(df_format[\"time taken\"].to_list())\n",
    "    \n",
    "    rsd = std_div / mean\n",
    "    \n",
    "    str_filesize = df_format[\"total filesize\"].iat[0]\n",
    "    filesize = float(str_filesize.split()[0])\n",
    "    unit = f\"{str_filesize.split()[1]}/s\"\n",
    "\n",
    "    throughput = filesize / mean\n",
    "    \n",
    "    tmp = pd.DataFrame(data=[{\"mean time\": mean, \"format\": format, \"engine\": df_format[\"engine\"].iat[0], \"run\": df_format[\"run\"].iat[0], \"total filesize\": df_format[\"total filesize\"].iat[0], \"throughput\": throughput, \"unit\": unit, \"relative standard deviation\": f\"{rsd:.2%}\"}])\n",
    "    smth = pd.concat([smth, tmp], ignore_index=True)\n",
    "    \n",
    "smth = smth[~smth[\"engine\"].isin([\"netcdf4-python\", \"hdf5-python\", \"zarr-python\"])]\n",
    "#smth = smth[~smth[\"total filesize\"].isin([\"50.0 GB\", \"60.0 GB\", \"70.0 GB\"])]\n",
    "\n",
    "#smth = smth[~(smth[\"engine\"].isin([\"netcdf4-python\"])) | (smth[\"total filesize\"].isin([\"10.0 GB\", \"20.0 GB\", \"30.0 GB\", \"40.0 GB\"]))]\n",
    "#smth = smth[~(smth[\"engine\"].isin([\"hdf5-python\"])) | (smth[\"total filesize\"].isin([\"10.0 GB\", \"20.0 GB\", \"70.0 GB\"]))]\n",
    "\n",
    "fig = px.box(\n",
    "    data_frame=smth,\n",
    "    log_y=True,\n",
    "    x=\"engine\",  \n",
    "    y=\"relative standard deviation\", \n",
    "    color=\"engine\", \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"relative standard deviation\": \"relative standard deviation (%)\"},\n",
    "    color_discrete_map={\n",
    "        \"zarr-python\": '#56B4E9',\n",
    "        \"netcdf4-python\": '#4B0092',\n",
    "        \"hdf5-python\": '#117733',\n",
    "        \"netcdf4-python-parallel\": '#FFB000',\n",
    "        \"hdf5-python-parallel\": '#FF4430',\n",
    "    },\n",
    "    )\n",
    "fig.update_traces(boxmean=True, showlegend=True)\n",
    "fig.add_shape(name=\"mean\", visible='legendonly', showlegend=True, type=\"line\", line=dict(dash=\"3px\"))\n",
    "fig.show()\n",
    "\n",
    "if save_image: fig.write_image(\"images/rsd-parallel.svg\", width=900, height=500, scale=1)\n",
    "\n",
    "smth = df\n",
    "#smth = smth[~smth[\"engine\"].isin([\"zarr-python\", \"netcdf4-python-parallel\", \"hdf5-python-parallel\"])]\n",
    "#smth = smth[~smth[\"total filesize\"].isin([\"20.0 GB\", \"30.0 GB\", \"40.0 GB\", \"50.0 GB\", \"60.0 GB\", \"70.0 GB\"])]\n",
    "\n",
    "fig = px.box(\n",
    "    data_frame=smth,\n",
    "    log_y=True, \n",
    "    x=\"total filesize\", \n",
    "    y=\"time taken\", \n",
    "    color=\"engine\",  \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"time taken\": \"time taken in seconds (s)\"},\n",
    "    color_discrete_map={\n",
    "        \"zarr-python\": '#56B4E9',\n",
    "        \"netcdf4-python\": '#4B0092',\n",
    "        \"hdf5-python\": '#117733',\n",
    "        \"netcdf4-python-parallel\": '#FFB000',\n",
    "        \"hdf5-python-parallel\": '#FF4430',\n",
    "    },\n",
    "    )\n",
    "fig.update_traces(boxmean=True, showlegend=True)\n",
    "fig.add_shape(name=\"mean\", visible='legendonly', showlegend=True, type=\"line\", line=dict(dash=\"3px\"))\n",
    "fig.show()\n",
    "    \n",
    "\n",
    "\n",
    "#################################################################################################################################################################################\n",
    "#################################################################################################################################################################################\n",
    "#################################################################################################################################################################################\n",
    "#################################################################################################################################################################################\n",
    "#################################################################################################################################################################################\n",
    "\n",
    "\n",
    "df = df_bench_c_copy\n",
    "\n",
    "# c plotting\n",
    "\n",
    "save_image = False\n",
    "\n",
    "#df = df[~df[\"engine\"].isin([\"netcdf4-c\", \"hdf5-c\"])]\n",
    "\n",
    "#df = df[df[\"engine\"].isin([\"netcdf4-c\"])]\n",
    "#df = df[df[\"engine\"].isin([\"hdf5-subfiling\"])]\n",
    "\n",
    "# plot development in time taken by chunksize\n",
    "filter = df[\"format\"].drop_duplicates(ignore_index=True)\n",
    "smth = pd.DataFrame()\n",
    "for format in filter:\n",
    "    mask = df[\"format\"].values == format\n",
    "    df_format = df[mask]\n",
    "    \n",
    "    mean =  np.mean(df_format[\"time taken\"].to_list())\n",
    "    str_filesize = df_format[\"total filesize\"].iat[0]\n",
    "    filesize = float(str_filesize.split()[0])\n",
    "    unit = f\"{str_filesize.split()[1]}/s\"\n",
    "\n",
    "    throughput = filesize / mean\n",
    "    \n",
    "    error = stats.sem(df_format[\"time taken\"].to_list())\n",
    "    \n",
    "    tmp = pd.DataFrame(data=[{\"error bar\": error, \"mean time\": mean, \"format\": format, \"engine\": df_format[\"engine\"].iat[0], \"run\": df_format[\"run\"].iat[0], \"total filesize\": df_format[\"total filesize\"].iat[0], \"throughput\": throughput, \"unit\":unit}])\n",
    "    smth = pd.concat([smth, tmp], ignore_index=True)\n",
    "\n",
    "fig = px.line(\n",
    "    data_frame=smth, \n",
    "    log_y=True, \n",
    "    x=\"total filesize\", \n",
    "    y=\"mean time\", \n",
    "    color=\"engine\", \n",
    "    markers=True, \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"mean time\": \"mean time in seconds (s)\"},\n",
    "    error_y=\"error bar\",\n",
    "    color_discrete_map={\n",
    "        \"netcdf4-c\": '#4B0092',\n",
    "        \"hdf5-c\": '#117733',\n",
    "        \"netcdf4-c-parallel\": '#FFB000',\n",
    "        \"hdf5-c-parallel\": '#FF4430',\n",
    "        \"hdf5-async\": '#56B4E9',\n",
    "        \"hdf5-subfiling\": '#AB029E',\n",
    "    },\n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "if save_image: fig.write_image(\"images/c-netcdf4.svg\", width=900, height=500, scale=1)\n",
    "\n",
    "unit = smth[\"unit\"].iat[0]\n",
    "fig = px.bar(\n",
    "    data_frame=smth, \n",
    "    x=\"total filesize\", \n",
    "    y=\"throughput\", \n",
    "    color=\"engine\", \n",
    "    barmode='group', \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"throughput\": f\"throughput in {unit}\"},\n",
    "    color_discrete_map={\n",
    "        \"netcdf4-c\": '#4B0092',\n",
    "        \"hdf5-c\": '#117733',\n",
    "        \"netcdf4-c-parallel\": '#FFB000',\n",
    "        \"hdf5-c-parallel\": '#FF4430',\n",
    "        \"hdf5-async\": '#56B4E9',\n",
    "        \"hdf5-subfiling\": '#AB029E',\n",
    "    },\n",
    "    )\n",
    "fig.show()\n",
    "#if save_image: fig.write_image(\"images/c-box-datarate-par.svg\", width=900, height=500, scale=1)\n",
    "\n",
    "\n",
    "save_image = False\n",
    "\n",
    "df = pd.concat([df_bench_python, df_bench_c_copy], ignore_index=True)\n",
    "\n",
    "# plotting both\n",
    "\n",
    "df = df[~df[\"engine\"].isin([\"netcdf4-python\", \"hdf5-python\", \"zarr-python\", \"netcdf4-c\", \"hdf5-c\"])]\n",
    "\n",
    "# plot development in time taken by chunksize\n",
    "filter = df[\"format\"].drop_duplicates(ignore_index=True)\n",
    "smth = pd.DataFrame()\n",
    "for format in filter:\n",
    "    mask = df[\"format\"].values == format\n",
    "    df_format = df[mask]\n",
    "    \n",
    "    mean =  np.mean(df_format[\"time taken\"].to_list())\n",
    "    str_filesize = df_format[\"total filesize\"].iat[0]\n",
    "    filesize = float(str_filesize.split()[0])\n",
    "    unit = f\"{str_filesize.split()[1]}/s\"\n",
    "\n",
    "    throughput = filesize / mean\n",
    "    \n",
    "    error = stats.sem(df_format[\"time taken\"].to_list())\n",
    "    \n",
    "    tmp = pd.DataFrame(data=[{\"error bar\": error, \"mean time\": mean, \"format\": format, \"engine\": df_format[\"engine\"].iat[0], \"run\": df_format[\"run\"].iat[0], \"total filesize\": df_format[\"total filesize\"].iat[0], \"throughput\": throughput, \"unit\":unit}])\n",
    "    smth = pd.concat([smth, tmp], ignore_index=True)\n",
    "\n",
    "fig = px.line(\n",
    "    data_frame=smth, \n",
    "    log_y=True, \n",
    "    x=\"total filesize\", \n",
    "    y=\"mean time\", \n",
    "    color=\"engine\", \n",
    "    markers=True, \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"mean time\": \"mean time in seconds (s)\"},\n",
    "    error_y=\"error bar\",\n",
    "    color_discrete_map={\n",
    "        \"zarr-python\": '#56B4E9',\n",
    "        \"netcdf4-python\": '#4B0092',\n",
    "        \"hdf5-python\": '#117733',\n",
    "        \"netcdf4-c\": '#FFB000',\n",
    "        \"hdf5-c\": '#FF4430',\n",
    "        \"netcdf4-python-parallel\": '#4B0092',\n",
    "        \"hdf5-python-parallel\": '#117733',\n",
    "        \"netcdf4-c-parallel\": '#FFB000',\n",
    "        \"hdf5-c-parallel\": '#FF4430',\n",
    "        \"hdf5-async\": '#56B4E9',\n",
    "        \"hdf5-subfiling\": '#AB029E',\n",
    "    },\n",
    "    )\n",
    "fig.show()\n",
    "if save_image: fig.write_image(\"images/both-line-total-filesize-ser.svg\", width=900, height=500, scale=1)\n",
    "\n",
    "unit = smth[\"unit\"].iat[0]\n",
    "fig = px.bar(\n",
    "    data_frame=smth, \n",
    "    x=\"total filesize\", \n",
    "    y=\"throughput\", \n",
    "    color=\"engine\", \n",
    "    barmode='group', \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"throughput\": f\"throughput in {unit}\"},\n",
    "    color_discrete_map={\n",
    "        \"zarr-python\": '#56B4E9',\n",
    "        \"netcdf4-python\": '#4B0092',\n",
    "        \"hdf5-python\": '#117733',\n",
    "        \"netcdf4-c\": '#FFB000',\n",
    "        \"hdf5-c\": '#FF4430',\n",
    "        \"netcdf4-python-parallel\": '#4B0092',\n",
    "        \"hdf5-python-parallel\": '#117733',\n",
    "        \"netcdf4-c-parallel\": '#FFB000',\n",
    "        \"hdf5-c-parallel\": '#FF4430',\n",
    "        \"hdf5-async\": '#56B4E9',\n",
    "        \"hdf5-subfiling\": '#AB029E',\n",
    "    },\n",
    "    )\n",
    "fig.show()\n",
    "if save_image: fig.write_image(\"images/both-box-datarate-ser.svg\", width=900, height=500, scale=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "616ce911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false --no-raise-error\n",
    "import pandas as pd\n",
    "\n",
    "df_bench_c = pd.read_json(\"data/plotting/plotting_bench_c_chunks.json\")\n",
    "df_bench_c_copy = pd.read_json(\"data/plotting/plotting_bench_c.json\")\n",
    "df_bench_python = pd.read_json(\"data/plotting/plotting_bench_python_chunks.json\")\n",
    "df_bench_python_copy = pd.read_json(\"data/plotting/plotting_bench_python copy.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = df_bench_python\n",
    "\n",
    "save_image = False\n",
    "\n",
    "# python plotting\n",
    "\n",
    "df = df[~df[\"engine\"].isin([\"zarr-python\", \"netcdf4-python\", \"hdf5-python\"])]\n",
    "\n",
    "# plot development in time taken by chunksize\n",
    "filter = df[\"format\"].drop_duplicates(ignore_index=True)\n",
    "smth = pd.DataFrame()\n",
    "for format in filter:\n",
    "    mask = df[\"format\"].values == format\n",
    "    df_format = df[mask]\n",
    "    \n",
    "    mean =  np.mean(df_format[\"time taken\"].to_list())\n",
    "    str_filesize = df_format[\"total filesize\"].iat[0]\n",
    "    filesize = float(str_filesize.split()[0])\n",
    "    unit = f\"{str_filesize.split()[1]}/s\"\n",
    "\n",
    "    throughput = filesize / mean\n",
    "    \n",
    "    error = stats.sem(df_format[\"time taken\"].to_list())\n",
    "    \n",
    "    tmp = pd.DataFrame(data=[{\"error bar\": error, \"mean time\": mean, \"format\": format, \"engine\": df_format[\"engine\"].iat[0], \"run\": df_format[\"run\"].iat[0], \"total filesize\": df_format[\"total filesize\"].iat[0], \"throughput\": throughput, \"unit\":unit, \"filesize per chunk\": df_format[\"filesize per chunk\"].iat[0]}])\n",
    "    smth = pd.concat([smth, tmp], ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "fig = px.line(\n",
    "    data_frame=smth, \n",
    "    log_y=True, \n",
    "    x=\"filesize per chunk\", \n",
    "    y=\"mean time\", \n",
    "    color=\"engine\", \n",
    "    markers=True, \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"mean time\": \"mean time in seconds (s)\"},\n",
    "    error_y=\"error bar\",\n",
    "    color_discrete_map={\n",
    "        \"zarr-python\": '#56B4E9',\n",
    "        \"netcdf4-python\": '#4B0092',\n",
    "        \"hdf5-python\": '#117733',\n",
    "        \"netcdf4-python-parallel\": '#FFB000',\n",
    "        \"hdf5-python-parallel\": '#FF4430',\n",
    "    },\n",
    "    )\n",
    "fig.show()\n",
    "if save_image: fig.write_image(\"images/python-line-total-filesize-chunks-par.svg\", width=900, height=500, scale=1)\n",
    "\n",
    "unit = smth[\"unit\"].iat[0]\n",
    "fig = px.bar(\n",
    "    data_frame=smth,\n",
    "    x=\"filesize per chunk\", \n",
    "    y=\"throughput\", \n",
    "    color=\"engine\", \n",
    "    barmode='group', \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"throughput\": f\"throughput in {unit}\"},\n",
    "    color_discrete_map={\n",
    "        \"zarr-python\": '#56B4E9',\n",
    "        \"netcdf4-python\": '#4B0092',\n",
    "        \"hdf5-python\": '#117733',\n",
    "        \"netcdf4-python-parallel\": '#FFB000',\n",
    "        \"hdf5-python-parallel\": '#FF4430',\n",
    "    },\n",
    "    )\n",
    "fig.show()\n",
    "if save_image: fig.write_image(\"images/python-box-datarate-chunks-par.svg\", width=900, height=500, scale=1)\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################################################################################################################\n",
    "######################################################################################################################################################################################\n",
    "######################################################################################################################################################################################\n",
    "######################################################################################################################################################################################\n",
    "######################################################################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "df = df_bench_c\n",
    "\n",
    "df = df[~df[\"engine\"].isin([\"hdf5-subfiling\", \"hdf5-async\", \"hdf5-c-parallel\", \"netcdf4-c-parallel\"])]\n",
    "\n",
    "# c plotting\n",
    "\n",
    "save_image = False\n",
    "\n",
    "# plot development in time taken by chunksize\n",
    "filter = df[\"format\"].drop_duplicates(ignore_index=True)\n",
    "smth = pd.DataFrame()\n",
    "for format in filter:\n",
    "    mask = df[\"format\"].values == format\n",
    "    df_format = df[mask]\n",
    "    \n",
    "    mean =  np.mean(df_format[\"time taken\"].to_list())\n",
    "    str_filesize = df_format[\"total filesize\"].iat[0]\n",
    "    filesize = float(str_filesize.split()[0])\n",
    "    unit = f\"{str_filesize.split()[1]}/s\"\n",
    "\n",
    "    throughput = filesize / mean\n",
    "    \n",
    "    error = stats.sem(df_format[\"time taken\"].to_list())\n",
    "    \n",
    "    tmp = pd.DataFrame(data=[{\"error bar\": error, \"mean time\": mean, \"format\": format, \"engine\": df_format[\"engine\"].iat[0], \"run\": df_format[\"run\"].iat[0], \"total filesize\": df_format[\"total filesize\"].iat[0], \"throughput\": throughput, \"unit\":unit, \"filesize per chunk\": df_format[\"filesize per chunk\"].iat[0]}])\n",
    "    smth = pd.concat([smth, tmp], ignore_index=True)\n",
    "\n",
    "fig = px.line(\n",
    "    data_frame=smth, \n",
    "    log_y=True, \n",
    "    x=\"filesize per chunk\", \n",
    "    y=\"mean time\", \n",
    "    color=\"engine\", \n",
    "    markers=True, \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"mean time\": \"mean time in seconds (s)\"},\n",
    "    error_y=\"error bar\",\n",
    "    color_discrete_map={\n",
    "        \"netcdf4-c\": '#4B0092',\n",
    "        \"hdf5-c\": '#117733',\n",
    "        \"netcdf4-c-parallel\": '#FFB000',\n",
    "        \"hdf5-c-parallel\": '#FF4430',\n",
    "        \"hdf5-async\": '#56B4E9',\n",
    "        \"hdf5-subfiling\": '#AB029E',\n",
    "    },\n",
    "    )\n",
    "fig.show()\n",
    "if save_image: fig.write_image(\"images/c-line-total-filesize-chunks-ser.svg\", width=900, height=500, scale=1)\n",
    "\n",
    "unit = smth[\"unit\"].iat[0]\n",
    "fig = px.bar(\n",
    "    data_frame=smth, \n",
    "    x=\"filesize per chunk\", \n",
    "    y=\"throughput\", \n",
    "    color=\"engine\", \n",
    "    barmode='group', \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"throughput\": f\"throughput in {unit}\"},\n",
    "    color_discrete_map={\n",
    "        \"netcdf4-c\": '#4B0092',\n",
    "        \"hdf5-c\": '#117733',\n",
    "        \"netcdf4-c-parallel\": '#FFB000',\n",
    "        \"hdf5-c-parallel\": '#FF4430',\n",
    "        \"hdf5-async\": '#56B4E9',\n",
    "        \"hdf5-subfiling\": '#AB029E',\n",
    "    },\n",
    "    )\n",
    "fig.show()\n",
    "if save_image: fig.write_image(\"images/c-box-datarate-chunks-ser.svg\", width=900, height=500, scale=1)\n",
    "\n",
    "\n",
    "save_image = False\n",
    "\n",
    "\n",
    "df = df_bench_both = pd.concat([df_bench_python, df_bench_c], ignore_index=True)\n",
    "\n",
    "df = df[~df[\"engine\"].isin([\"netcdf4-python-parallel\", \"hdf5-python-parallel\", \"hdf5-subfiling\", \"hdf5-async\", \"hdf5-c-parallel\", \"netcdf4-c-parallel\"])]\n",
    "\n",
    "# plotting both\n",
    "\n",
    "# plot development in time taken by chunksize\n",
    "filter = df[\"format\"].drop_duplicates(ignore_index=True)\n",
    "smth = pd.DataFrame()\n",
    "for format in filter:\n",
    "    mask = df[\"format\"].values == format\n",
    "    df_format = df[mask]\n",
    "    \n",
    "    mean =  np.mean(df_format[\"time taken\"].to_list())\n",
    "    str_filesize = df_format[\"total filesize\"].iat[0]\n",
    "    filesize = float(str_filesize.split()[0])\n",
    "    unit = f\"{str_filesize.split()[1]}/s\"\n",
    "\n",
    "    throughput = filesize / mean\n",
    "    \n",
    "    error = stats.sem(df_format[\"time taken\"].to_list())\n",
    "    \n",
    "    tmp = pd.DataFrame(data=[{\"error bar\": error, \"mean time\": mean, \"format\": format, \"engine\": df_format[\"engine\"].iat[0], \"run\": df_format[\"run\"].iat[0], \"total filesize\": df_format[\"total filesize\"].iat[0], \"throughput\": throughput, \"unit\":unit, \"filesize per chunk\": df_format[\"filesize per chunk\"].iat[0]}])\n",
    "    smth = pd.concat([smth, tmp], ignore_index=True)\n",
    "\n",
    "fig = px.line(\n",
    "    data_frame=smth, \n",
    "    log_y=True, \n",
    "    x=\"filesize per chunk\", \n",
    "    y=\"mean time\", \n",
    "    color=\"engine\", \n",
    "    markers=True, \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"mean time\": \"mean time in seconds (s)\"},\n",
    "    error_y=\"error bar\",\n",
    "    color_discrete_map={\n",
    "        \"zarr-python\": '#56B4E9',\n",
    "        \"netcdf4-python\": '#4B0092',\n",
    "        \"hdf5-python\": '#117733',\n",
    "        \"netcdf4-c\": '#FFB000',\n",
    "        \"hdf5-c\": '#FF4430',\n",
    "        \"netcdf4-python-parallel\": '#4B0092',\n",
    "        \"hdf5-python-parallel\": '#117733',\n",
    "        \"netcdf4-c-parallel\": '#FFB000',\n",
    "        \"hdf5-c-parallel\": '#FF4430',\n",
    "        \"hdf5-async\": '#56B4E9',\n",
    "        \"hdf5-subfiling\": '#AB029E',\n",
    "    },\n",
    "    )\n",
    "fig.show()\n",
    "if save_image: fig.write_image(\"images/both-line-total-filesize-chunks-par.svg\", width=900, height=500, scale=1)\n",
    "\n",
    "unit = smth[\"unit\"].iat[0]\n",
    "fig = px.bar(\n",
    "    data_frame=smth, \n",
    "    x=\"filesize per chunk\", \n",
    "    y=\"throughput\", \n",
    "    color=\"engine\", \n",
    "    barmode='group', \n",
    "    hover_data=[\"format\"], \n",
    "    labels={\"throughput\": f\"throughput in {unit}\"},\n",
    "    color_discrete_map={\n",
    "        \"zarr-python\": '#56B4E9',\n",
    "        \"netcdf4-python\": '#4B0092',\n",
    "        \"hdf5-python\": '#117733',\n",
    "        \"netcdf4-c\": '#FFB000',\n",
    "        \"hdf5-c\": '#FF4430',\n",
    "        \"netcdf4-python-parallel\": '#4B0092',\n",
    "        \"hdf5-python-parallel\": '#117733',\n",
    "        \"netcdf4-c-parallel\": '#FFB000',\n",
    "        \"hdf5-c-parallel\": '#FF4430',\n",
    "        \"hdf5-async\": '#56B4E9',\n",
    "        \"hdf5-subfiling\": '#AB029E',\n",
    "    },\n",
    "    )\n",
    "fig.show()\n",
    "if save_image: fig.write_image(\"images/both-box-datarate-chunks-par.svg\", width=900, height=500, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97166a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot runs by engine\n",
    "fig = px.box(data_frame=df, log_y=True, x=\"engine\", y=\"time taken\", color=\"run\", hover_data=[\"format\", \"filesize per chunk\"])\n",
    "fig.show()\n",
    "\n",
    "# plot formats by chunksize\n",
    "fig = px.box(data_frame=df, log_y=True, x=\"total filesize\", y=\"time taken\", color=\"engine\", hover_data=[\"format\", \"filesize per chunk\"], title=\"total filesize\")\n",
    "fig.show()\n",
    "\n",
    "filter = df[\"engine\"].drop_duplicates(ignore_index=True)\n",
    "\n",
    "for engine in filter:\n",
    "    \n",
    "    mask = df[\"engine\"].values == engine\n",
    "    df_engine = df[mask]\n",
    "    fig =  fig = px.box(data_frame=df_engine, log_y=True, x=\"engine\", y=\"time taken\", color=\"total filesize\",)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "filter = df[\"run\"].drop_duplicates(ignore_index=True)\n",
    "\n",
    "fig = px.violin(data_frame=df, log_x=True, x=\"time taken\", y=\"format\", color=\"engine\")\n",
    "fig.show()\n",
    "\n",
    "for engine in filter:\n",
    "    \n",
    "    mask = df[\"run\"].values == engine\n",
    "    fig = px.box(data_frame=df[mask], log_y=True, x=\"engine\", y=\"time taken\", color=\"total filesize\", points=\"all\",)\n",
    "    #fig.show()\n",
    "    \n",
    "    fig = px.violin(data_frame=df[mask], log_x=True, x=\"time taken\", y=\"total filesize\", color=\"engine\")\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
