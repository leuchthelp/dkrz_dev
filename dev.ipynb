{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d441978f431651b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T16:27:49.636653Z",
     "start_time": "2024-12-12T16:27:49.571404Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "import zarr\n",
    "from netCDF4 import Dataset\n",
    "if __name__ == '__main__':\n",
    "    #Todo read up on hdf5, zarr, netcdf, xarray, mpi, lustre, ceph\n",
    "    # and check back with dkrz their structure, code conventions, datasets\n",
    "\n",
    "    # Todo setup test cases proactively to ensure proper comparability and best practice\n",
    "\n",
    "    #Todo use netcdf dataset for testing (for now) should already bet hdf5\n",
    "    dest_hdf = Dataset(\"data/source.nc\", \"w\", format=\"NETCDF4\")\n",
    "    print(dest_hdf.data_model)\n",
    "    dest_hdf.close()\n",
    "\n",
    "    #Todo import netcdf data through hdf5 to zarr (for now)\n",
    "    dest_zarr = zarr.open_group('data/example2.zarr', mode='w')\n",
    "    zarr.copy_all(dest_hdf, dest_zarr)\n",
    "    dest_zarr.tree()\n",
    "\n",
    "    #Todo conversion to netcdf\n",
    "\n",
    "    #for hdf5 nothing needs to be done\n",
    "\n",
    "    #for zarr (wip). netcdf is developing its own implementation\n",
    "    # but that isn't available yet so I will work on something myself in the meantime\n",
    "\n",
    "    #Todo setup Lustre and Ceph (need info on that)\n",
    "\n",
    "    #Todo setup benchmark (prob compression, filesize, access-time, r/w-time) for sequential access\n",
    "\n",
    "    #Todo setup benchmark for parallel access\n",
    "\n",
    "    #Todo setup benchmark for random access\n",
    "\n",
    "    #Todo setup benchmark for parallel with subfileing and async / I/O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316211b7bd13977d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T16:27:49.652330Z",
     "start_time": "2024-12-12T16:27:49.648971Z"
    }
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "rank = MPI.COMM_WORLD.rank\n",
    "\n",
    "# create HDF5 file\n",
    "with h5py.File('data/test_ds.hdf5', 'w', driver=\"mpio\", comm=MPI.COMM_WORLD) as hf:\n",
    "    u = hf.create_dataset(\"u\", data=np.random.rand(1_000_000, 10, 10, 1), shape=(1_000_000, 10, 10, 1), compression=\"gzip\", chunks=True)\n",
    "    v = hf.create_dataset(\"v\", data=np.random.rand(1_000_000, 10, 10, 1), shape=(1_000_000, 10, 10, 1), compression=\"gzip\", chunks=True)\n",
    "    w = hf.create_dataset(\"w\", data=np.random.rand(1_000_000, 10, 10, 1), shape=(1_000_000, 10, 10, 1), compression=\"gzip\", chunks=True)\n",
    "    x = hf.create_dataset(\"x\", data=np.random.rand(1_000_000, 10, 10, 1), shape=(1_000_000, 10, 10, 1), compression=\"gzip\", chunks=True)\n",
    "    y = hf.create_dataset(\"y\", data=np.random.rand(1_000_000, 10, 10, 1), shape=(1_000_000, 10, 10, 1), compression=\"gzip\", chunks=True)\n",
    "\n",
    "hf.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93924c7b041d484",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-12T16:27:49.713786Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:20\u001b[0m\n",
      "File \u001b[0;32m~/dkrz_dev/.venv/lib/python3.10/site-packages/xarray/core/dataset.py:2372\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[1;32m   2369\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2370\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 2372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[1;32m   2373\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2376\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2380\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2383\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dkrz_dev/.venv/lib/python3.10/site-packages/xarray/backends/api.py:1873\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# TODO: figure out how to refactor this logic (here and in save_mfdataset)\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# to avoid this mess of conditionals\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1871\u001b[0m     \u001b[38;5;66;03m# TODO: allow this work (setting up the file for writing array data)\u001b[39;00m\n\u001b[1;32m   1872\u001b[0m     \u001b[38;5;66;03m# to be parallelized with dask\u001b[39;00m\n\u001b[0;32m-> 1873\u001b[0m     \u001b[43mdump_to_store\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\n\u001b[1;32m   1875\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m autoclose:\n\u001b[1;32m   1877\u001b[0m         store\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/dkrz_dev/.venv/lib/python3.10/site-packages/xarray/backends/api.py:1920\u001b[0m, in \u001b[0;36mdump_to_store\u001b[0;34m(dataset, store, writer, encoder, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder:\n\u001b[1;32m   1918\u001b[0m     variables, attrs \u001b[38;5;241m=\u001b[39m encoder(variables, attrs)\n\u001b[0;32m-> 1920\u001b[0m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dkrz_dev/.venv/lib/python3.10/site-packages/xarray/backends/common.py:451\u001b[0m, in \u001b[0;36mAbstractWritableDataStore.store\u001b[0;34m(self, variables, attributes, check_encoding_set, writer, unlimited_dims)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_attributes(attributes)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_dimensions(variables, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims)\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_variables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_encoding_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dkrz_dev/.venv/lib/python3.10/site-packages/xarray/backends/common.py:493\u001b[0m, in \u001b[0;36mAbstractWritableDataStore.set_variables\u001b[0;34m(self, variables, check_encoding_set, writer, unlimited_dims)\u001b[0m\n\u001b[1;32m    488\u001b[0m check \u001b[38;5;241m=\u001b[39m vn \u001b[38;5;129;01min\u001b[39;00m check_encoding_set\n\u001b[1;32m    489\u001b[0m target, source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_variable(\n\u001b[1;32m    490\u001b[0m     name, v, check, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims\n\u001b[1;32m    491\u001b[0m )\n\u001b[0;32m--> 493\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dkrz_dev/.venv/lib/python3.10/site-packages/xarray/backends/common.py:338\u001b[0m, in \u001b[0;36mArrayWriter.add\u001b[0;34m(self, source, target, region)\u001b[0m\n\u001b[1;32m    336\u001b[0m     target[region] \u001b[38;5;241m=\u001b[39m source\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m source\n",
      "File \u001b[0;32m~/dkrz_dev/.venv/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:83\u001b[0m, in \u001b[0;36mBaseNetCDF4Array.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     81\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_array(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     82\u001b[0m data[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mautoclose:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mclose(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "u = np.random.rand(1_000_000, 10, 10, 1)\n",
    "v = np.random.rand(1_000_000, 10, 10, 1)\n",
    "w = np.random.rand(1_000_000, 10, 10, 1)\n",
    "x = np.random.rand(1_000_000, 10, 10, 1)\n",
    "y = np.random.rand(1_000_000, 10, 10, 1)\n",
    "z = np.random.rand(1_000_000, 10, 10, 1)\n",
    "\n",
    "ds = xr.Dataset(data_vars=dict(\n",
    "                            u=([\"1\",\"2\",\"3\",\"4\"], u),\n",
    "                            v=([\"1\",\"2\",\"3\",\"4\"], v),\n",
    "                            w=([\"1\",\"2\",\"3\",\"4\"], w),\n",
    "                            x=([\"1\",\"2\",\"3\",\"4\"], x),\n",
    "                            y=([\"1\",\"2\",\"3\",\"4\"], y),\n",
    "                            z=([\"1\",\"2\",\"3\",\"4\"], z)\n",
    "                            ))\n",
    "\n",
    "ds.to_netcdf('data/test_dataset.nc', mode=\"w\")\n",
    "\n",
    "ds.to_netcdf('data/test_dataset.hdf5', mode=\"w\", engine=\"h5netcdf\")\n",
    "\n",
    "ds.to_zarr(\"data/test_dataset.zarr\", mode=\"w\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff585ad6e144f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.59 s, sys: 57.3 ms, total: 1.64 s\n",
      "Wall time: 336 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import xarray as xr\n",
    "ds_zarr = xr.open_zarr('data/test_dataset.zarr', consolidated=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37e8dda5b5ccdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 468 ms, sys: 551 ms, total: 1.02 s\n",
      "Wall time: 434 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import xarray as xr\n",
    "max_var = ds_zarr[\"x\"].max().compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a1222041420b736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.27 ms, sys: 0 ns, total: 9.27 ms\n",
      "Wall time: 7.95 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import xarray as xr\n",
    "ds_netcdf4 = xr.open_dataset(filename_or_obj=\"data/test_dataset.nc\", engine=\"h5netcdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd381f7ab539d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 ms, sys: 2.8 ms, total: 17.8 ms\n",
      "Wall time: 15.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import xarray as xr\n",
    "max_var = ds_netcdf4[\"x\"].max().compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
